# -*- coding: utf-8 -*-
"""SciBERT_for_foodsci_sentiment_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14WpXWg52JOXiL6pEfPzOG2NF1qiX_P1H

**Outline**

1) Use frozen SciBERT model to transform abstracts into word embeddings

2) Train CNN using PyTorch to identify positive results

Code adapted from [this blog post](https://towardsdatascience.com/identifying-hate-speech-with-bert-and-cnn-b7aa2cddd60d)
"""
# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import random
import logging
import time
import datetime
from platform import python_version
import numpy as np
import pandas as pd
import sklearn
import torch
import torch.nn as nn
import torch.nn.functional as F
import transformers
from sklearn.metrics import roc_auc_score
from torch.autograd import Variable

#Always make sure we're on GPU

if torch.cuda.is_available():
    # Tell PyTorch to use the GPU.
    device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())

    print('We will use the GPU:', torch.cuda.get_device_name(0))

# If not...
else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

#Load data and apply polarity rule
from pathlib import Path

data_path = str(Path(__file__).parent / "../Data")
mturk_abstracts = pd.read_csv(data_path + "/mturk_train.csv")

#Polarity rule: If >=2 positive ratings, then label positive
mturk_abstracts['polarity'] = (mturk_abstracts['count_pos'] >= 2).astype(int)

abstracts = mturk_abstracts['inputtext'].tolist()
labels = mturk_abstracts['polarity'].tolist()

assert len(abstracts) == len(labels)

from sklearn.model_selection import train_test_split

#Split into train and test sets
train_abstracts, test_abstracts, train_labels, test_labels = train_test_split(abstracts, labels, test_size = 0.1, random_state=2020)

print("Training set {} positive coded out of {} samples".format(sum([x==1 for x in train_labels]), len(train_labels)))
print("Testing set {} positive coded out of {} samples".format(sum([x==1 for x in test_labels]), len(test_labels)))

#Load SciBERT tokenizer and model
model_class = transformers.BertModel
config_class = transformers.BertConfig
tokenizer_class = transformers.BertTokenizer
pretrained_weights = 'allenai/scibert_scivocab_uncased'

print("Loading SciBERT tokenizer...")
tokenizer = tokenizer_class.from_pretrained(pretrained_weights)

print("Loading SciBERT model...")
config = config_class.from_pretrained(pretrained_weights, output_hidden_states = True)
bert_model = model_class.from_pretrained(pretrained_weights, config = config)
bert_model.eval()

#Get max sequence length
max_len = 0
for a in abstracts:
    encoded_dict = tokenizer.encode_plus(a, add_special_tokens=True, return_attention_mask = True)
    temp_len = len(encoded_dict['input_ids'])
    if temp_len > max_len:
        max_len = temp_len

print("Max encoded length found:",max_len)

#Define method to truncate from center
def truncateCenter(s, maxlen):
    ret = s
    while len(ret) > maxlen:
        ret = ret[:len(ret)//2-1] + ret[len(ret)//2+1:] #Remove middle two tokens
    return ret

#Encode abstracts, set truncation and padding, and return as PyTorch tensors
def getTokens(maxlen):
    MAX_LEN = min(512, maxlen) #BERT can only take maximum sequence of 512

    train_input_list = []
    train_attention_list = []

    for a in train_abstracts:
        tokenized = tokenizer.tokenize(a)
        trunc_tokens = truncateCenter(tokenized, MAX_LEN) #Truncate from center
        encoded_dict = tokenizer.encode_plus(trunc_tokens, max_length = MAX_LEN, pad_to_max_length=True,
                                      add_special_tokens=True, return_attention_mask = True,
                                      return_tensors='pt')
        train_input_list.append(encoded_dict['input_ids'])
        train_attention_list.append(encoded_dict['attention_mask'])

    test_input_list = []
    test_attention_list = []

    for a in test_abstracts:
        tokenized = tokenizer.tokenize(a)
        trunc_tokens = truncateCenter(tokenized, MAX_LEN) #Truncate from center
        encoded_dict = tokenizer.encode_plus(trunc_tokens, max_length = MAX_LEN, pad_to_max_length=True,
                                      add_special_tokens=True, return_attention_mask = True,
                                      return_tensors='pt')
        test_input_list.append(encoded_dict['input_ids'])
        test_attention_list.append(encoded_dict['attention_mask'])

    #Convert lists into tensors
    train_input_tensor = torch.cat(train_input_list, dim=0)
    test_input_tensor = torch.cat(test_input_list, dim=0)
    train_attention_tensor = torch.cat(train_attention_list, dim=0)
    test_attention_tensor = torch.cat(test_attention_list, dim=0)
    train_label_tensor = torch.tensor(train_labels)
    test_label_tensor = torch.tensor(test_labels)

    #Split input data into chunks to go easy on RAM
    train_input_split = torch.split(train_input_tensor, 10)
    test_input_split = torch.split(test_input_tensor, 10)
    train_attention_split = torch.split(train_attention_tensor, 10)
    test_attention_split = torch.split(test_attention_tensor, 10)

    for i in range(len(train_input_split)):
        assert len(train_input_split[i]) == len(train_attention_split[i])

    return train_input_split, test_input_split, train_attention_split, test_attention_split, train_label_tensor, test_label_tensor
"""Transformers BERT hidden state output structure:

Index 0 = initial input embedding

Index 12 = output of last layers (equivalent to last hidden state)

Different combinations of layer outputs alter performance...see [this embeddings tutorial](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#3-extracting-embeddings)

We will try: last layer, second-to-last layer, concat last 4 layers, sum last 4, sum all 12 layers
"""

import os
import psutil
import humanize

def getEmbeddings(strat):
  x_train_list, x_test_list = [], []
  if strat == "last":
      for i in range(len(train_input_split)):
          with torch.no_grad():
              x_train = bert_model(input_ids=train_input_split[i], attention_mask=train_attention_split[i])[0]
              x_train_list.append(x_train)
              if i < len(test_input_split):
                  x_test = bert_model(input_ids=test_input_split[i], attention_mask=test_attention_split[i])[0]
                  x_test_list.append(x_test)
          #Get process memory for each loop
          process = psutil.Process(os.getpid())
          print("Gen RAM Free: " + humanize.naturalsize(psutil.virtual_memory().available), " |     Proc size: " + humanize.naturalsize(process.memory_info().rss))
  elif strat == "secondtolast":
      for i in range(len(train_input_split)):
          with torch.no_grad():
              x_train = bert_model(input_ids=train_input_split[i], attention_mask=train_attention_split[i])[2]
              x_train = torch.stack(x_train, dim = 0)[-2] #(13, bsize, seq_length, n_bert_features = 768)
              x_train_list.append(x_train)
              if i < len(test_input_split):
                  x_test = bert_model(input_ids=test_input_split[i], attention_mask=test_attention_split[i])[2]
                  x_test = torch.stack(x_test, dim = 0)[-2]
                  x_test_list.append(x_test)
  elif strat == "sum4":
      for i in range(len(train_input_split)):
          with torch.no_grad():
              x_train = bert_model(input_ids=train_input_split[i], attention_mask=train_attention_split[i])[2]
              x_train = torch.stack(x_train, dim = 0) #(13, bsize, seq_length, n_bert_features = 768)
              x_train = torch.sum(x_train[-4:], dim = 0) #(bsize, seq_length, n_bert_features = 768)
              x_train_list.append(x_train)
              if i < len(test_input_split):
                  x_test = bert_model(input_ids=test_input_split[i], attention_mask=test_attention_split[i])[2]
                  x_test = torch.stack(x_test, dim = 0)
                  x_test = torch.sum(x_test[-4:], dim = 0)
                  x_test_list.append(x_test)
  elif strat == "sumall":
      for i in range(len(train_input_split)):
          with torch.no_grad():
              x_train = bert_model(input_ids=train_input_split[i], attention_mask=train_attention_split[i])[2]
              x_train = torch.stack(x_train, dim = 0) #(13, bsize, seq_length, n_bert_features = 768)
              x_train = torch.sum(x_train[-12:], dim = 0) #(bsize, seq_length, n_bert_features = 768)
              x_train_list.append(x_train)
              if i < len(test_input_split):
                  x_test = bert_model(input_ids=test_input_split[i], attention_mask=test_attention_split[i])[2]
                  x_test = torch.stack(x_test, dim = 0)
                  x_test = torch.sum(x_test[-12:], dim = 0)
                  x_test_list.append(x_test)
  elif strat == "concat4":
      for i in range(len(train_input_split)):
          with torch.no_grad():
              x_train = bert_model(input_ids=train_input_split[i], attention_mask=train_attention_split[i])[2]
              x_train = torch.stack(x_train, dim = 0) #(13, bsize, seq_length, n_bert_features = 768)
              x_train = [x_train[-4], x_train[-3], x_train[-2], x_train[-1]] #(bsize, seq_length, n_bert_features*4 = 3072)
              x_train = torch.cat(x_train, dim = 1)
              x_train_list.append(x_train)
              if i < len(test_input_split):
                  x_test = bert_model(input_ids=test_input_split[i], attention_mask=test_attention_split[i])[2]
                  x_test = torch.stack(x_test, dim = 0)
                  x_test = [x_test[-4], x_test[-3], x_test[-2], x_test[-1]] #(bsize, seq_length, n_bert_features*4 = 3072)
                  x_test = torch.cat(x_test, dim = 1)
                  x_test_list.append(x_test)
  else:
    raise Exception("Invalid pooling strategy {}".format(strat))

  return x_train_list, x_test_list

#Define helper functions

#Accuracy function
def flat_accuracy(preds, labels):
    pred_flat = np.round(preds.flatten()).astype(int) #Map probabilities to predictions
    labels_flat = labels.flatten().astype(int)
    return np.sum(pred_flat == labels_flat) / len(labels_flat)

def format_time(elapsed):
    '''
    Takes a time in seconds and returns a string hh:mm:ss
    '''
    # Round to the nearest second.
    elapsed_rounded = int(round((elapsed)))

    # Format as hh:mm:ss
    return str(datetime.timedelta(seconds=elapsed_rounded))

"""
Train convolutional network for sentiment analysis. Based on
"Convolutional Neural Networks for Sentence Classification" by Yoon Kim
http://arxiv.org/pdf/1408.5882v2.pdf
"""

class KimCNN(nn.Module):
    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):
        super(KimCNN, self).__init__()
        V = embed_num
        D = embed_dim
        C = class_num
        Co = kernel_num
        Ks = kernel_sizes

        self.static = static
        self.embed = nn.Embedding(V, D)
        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])
        self.dropout = nn.Dropout(dropout)
        self.fc1 = nn.Linear(len(Ks) * Co, C)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        if self.static:
            x = Variable(x)
        x = x.unsqueeze(1)  # (N, Ci, W, D)
        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)
        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)
        x = torch.cat(x, 1)
        x = self.dropout(x)  # (N, len(Ks)*Co)
        logit = self.fc1(x)  # (N, C)
        output = self.sigmoid(logit)
        return output

from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
def createDataLoaders(x_train, x_test, train_label_tensor, test_label_tensor, batch_size = 32):
  batch_size = batch_size

  #Create DataLoaders for training/validation
  train_tdata = TensorDataset(x_train, train_label_tensor)
  test_tdata = TensorDataset(x_test, test_label_tensor)

  train_sampler = RandomSampler(x_train)
  test_sampler = SequentialSampler(x_test)

  train_dataloader = DataLoader(train_tdata, sampler = train_sampler, batch_size = batch_size)
  test_dataloader = DataLoader(test_tdata, sampler = test_sampler, batch_size = batch_size)

  return train_dataloader, test_dataloader

#Train CNN model
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
path = str(Path(__file__).parent / "../Plots")

def train(model):
  #Set seed
  seed_val = 2020
  random.seed(seed_val)
  np.random.seed(seed_val)
  torch.manual_seed(seed_val)
  torch.cuda.manual_seed_all(seed_val)

  #Record loss and accuracy
  train_loss = []
  test_loss = []
  train_acc = []
  test_acc = []
  test_preds_csv_list = []
  t_init = time.time()
  for epoch_i in range(n_epochs):
    #====================
    #     Training
    #====================
    print("")
    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, n_epochs))
    print('Training...')
    t0 = time.time()
    total_loss = 0
    total_accuracy = 0
    steps = 0
    model.train() #Put into training mode

    for step, batch in enumerate(train_dataloader):
      #Progress update every 5 batches
      if step % 5 == 0 and not step == 0:
        elapsed = format_time(time.time() - t0)
        print('  Batch {}  of  {}.    Elapsed: {}.'.format(step, len(train_dataloader), elapsed))

      #Unpack batch and copy tensors to GPU
      b_input_encodings = batch[0].to(device)
      b_labels = batch[1].to(device)

      #Make sure to zero out the gradient
      model.zero_grad()

      #Perform forward pass
      outputs = model(b_input_encodings) #Sigmoid function output 0-1

      #Get loss
      loss = loss_fn(torch.squeeze(outputs), b_labels.float())
      total_loss += loss.item()

      #Move logits and labels to CPU - can't perform accuracy calculation on GPU
      outputs = outputs.detach().cpu().numpy()
      label_ids = b_labels.to('cpu').numpy()

      #Calculate batch accuracy
      tmp_accuracy = flat_accuracy(outputs, label_ids)
      total_accuracy += tmp_accuracy
      steps += 1

      #Backward pass to calculate gradients
      loss.backward()

      '''#Clip norms to prevent "exploding gradients"
      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)'''

      optimizer.step() #Update parameters using optimizer

    #Average loss/accuracy
    avg_loss = total_loss/steps
    avg_acc = total_accuracy/steps

    train_loss.append(avg_loss)
    train_acc.append(avg_acc)
    print("")
    print("  Average training loss: {0:.2f}".format(avg_loss))
    print("  Average training accuracy: {0:.2f}".format(avg_acc))
    print("  Training epoch took: {:}".format(format_time(time.time() - t0)))

    #====================
    #     Validation
    #====================
    print("")
    print("Running validation...")
    t0 = time.time()
    total_loss = 0
    total_accuracy = 0
    steps = 0
    preds = []
    targets = []

    model.eval() #Evaluation mode

    for batch in test_dataloader:
      #Unpack batch and copy tensors to GPU
      b_input_encodings = batch[0].to(device)
      b_labels = batch[1].to(device)

      #Tell model not to store gradients - speeds up testing
      with torch.no_grad():
        outputs = model(b_input_encodings)

      #Get loss
      loss = loss_fn(torch.squeeze(outputs), b_labels.float())
      total_loss += loss.item()

      #Move logits and labels to CPU - can't perform accuracy calculation on GPU
      outputs = outputs.detach().cpu().numpy()
      label_ids = b_labels.to('cpu').numpy()

      #Calculate batch accuracy
      tmp_accuracy = flat_accuracy(outputs, label_ids)
      total_accuracy += tmp_accuracy

      steps += 1 #Track batch num

      #Save predicted values
      preds.extend(outputs)
      targets.extend(label_ids)

    #Report the final accuracy for this validation run.
    test_loss.append(total_loss/steps)
    test_acc.append(total_accuracy/steps)
    print("  Average validation loss: {0:.2f}".format(total_loss/steps))
    print("  Average validation accuracy: {0:.2f}".format(total_accuracy/steps))
    print("  Validation took: {:}".format(format_time(time.time() - t0)))
    predict_csv = pd.DataFrame({"Prediction Probs":preds, "Labels":targets, "Epoch":epoch_i})
    test_preds_csv_list.append(predict_csv)

  print("Training complete!")
  print("Total training took {:} (h:mm:ss)".format(format_time(time.time()-t_init)))

  #Plot results
  loss_fname = "dropout{}_maxlen{}_bsize{}_loss.png".format(dropout, maxlen, bsize)
  acc_fname = "dropout{}_maxlen{}_bsize{}_acc.png".format(dropout, maxlen, bsize)

  plt.plot(train_loss, 'r--')
  plt.plot(test_loss, 'b-')
  plt.legend(['Training Loss', 'Validation Loss'])
  plt.title("Loss by Epoch")
  plt.xlabel("Epoch")
  plt.ylabel("Loss")
  plt.savefig(path + "/" + loss_fname)
  plt.clf()

  plt.plot(train_acc, 'r--')
  plt.plot(test_acc, 'b-')
  plt.legend(['Training Accuracy', 'Validation Accuracy'])
  plt.title("Accuracy by Epoch")
  plt.xlabel("Epoch")
  plt.ylabel("Accuracy")
  plt.savefig(path + "/" + acc_fname)
  plt.clf()

  #Download plots (in case session crashes)
  #downloadPlots(loss_fname)
  #downloadPlots(acc_fname)

n_epochs = 50
loss_fn = nn.BCELoss()

from transformers import get_linear_schedule_with_warmup

#Loop through different parameters configs and fine-tune
for bsize in [64, 128]:
  for d in [0.3, 0.5]:
      for maxlen in [256, 512]:
          strat = 'concat4'
          train_input_split, test_input_split, train_attention_split,test_attention_split, train_label_tensor, test_label_tensor = getTokens(maxlen)
          t0 = time.time()
          print("Running embedding strategy {}".format(strat))
          x_train_list, x_test_list = getEmbeddings(strat)
          print("Embeddings took {}".format(format_time(time.time() - t0)))

          x_train = torch.cat(x_train_list, dim=0)
          x_test = torch.cat(x_test_list, dim=0)
          print("Input shape:", x_train[0].size())
          print("Input set length:", len(x_train))
          print("Test set length:", len(x_test))

          train_dataloader, test_dataloader = createDataLoaders(x_train, x_test, train_label_tensor, test_label_tensor, bsize)
          embed_num = x_train.shape[1]
          embed_dim = x_train.shape[2]
          class_num = 1
          kernel_num = 8
          kernel_sizes = [2,3,8]
          dropout = d
          static = False
          model = KimCNN(
                      embed_num=embed_num,
                      embed_dim=embed_dim,
                      class_num=class_num,
                      kernel_num=kernel_num,
                      kernel_sizes=kernel_sizes,
                      dropout=dropout,
                      static=static,
                  )
          model.cuda()
          optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)
          train(model)
